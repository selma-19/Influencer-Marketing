{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T20:07:40.592278700Z",
     "start_time": "2024-05-06T20:07:40.522633800Z"
    }
   },
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import services.influencers_service as influencers_service\n",
    "#visualisation \n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "import json \n",
    "import glob\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "posts=influencers_service.get_posts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T20:07:40.635417900Z",
     "start_time": "2024-05-06T20:07:40.532162600Z"
    }
   },
   "id": "d3935b9537cce65e",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "def merge_content_posts(posts) : \n",
    "    #concatenation of captions of all posts\n",
    "    merged_content = \"\"\n",
    "    for post in posts:\n",
    "         #extract caption text\n",
    "         caption = post.get('caption')\n",
    "         if (caption):\n",
    "            merged_content += caption + \" \"\n",
    "    return merged_content"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T20:07:40.635417900Z",
     "start_time": "2024-05-06T20:07:40.542023400Z"
    }
   },
   "id": "6c2fc0c4e6d7d0b1",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def gen_words(text):\n",
    "    words=[]\n",
    "    new = gensim.utils.simple_preprocess(text, deacc=True)    \n",
    "    words.append(new)\n",
    "    return words"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T20:07:40.635417900Z",
     "start_time": "2024-05-06T20:07:40.557743700Z"
    }
   },
   "id": "528624ed0c398732",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "def gen_bow(words):\n",
    "    id2word = corpora.Dictionary(words)\n",
    "    corpus=[]\n",
    "    for word in words: \n",
    "        new = id2word.doc2bow(word)\n",
    "        corpus.append(new)\n",
    "    return  corpus"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T20:07:40.636426900Z",
     "start_time": "2024-05-06T20:07:40.567874700Z"
    }
   },
   "id": "8e08f19493148dbe",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "def make_bigrams(texts,bigram):\n",
    "    return [bigram[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts,bigram,trigram):\n",
    "    return [trigram[bigram[doc]] for doc in texts]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T20:07:40.637432600Z",
     "start_time": "2024-05-06T20:07:40.579065900Z"
    }
   },
   "id": "2264c5dfce18f4f",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# posts=posts[0:3] #for rapid testing we only use three posts\n",
    "merge=merge_content_posts(posts)\n",
    "# print(merge)\n",
    "words=gen_words(merge)\n",
    "# print(words)\n",
    "\n",
    "##generate bigrams and tigrams##\n",
    "bigram_phrases = gensim.models.Phrases(words, min_count=5, threshold=100)\n",
    "trigram_phrases = gensim.models.Phrases(bigram_phrases[words], threshold=100)\n",
    "bigram = gensim.models.phrases.Phraser(bigram_phrases)\n",
    "trigram = gensim.models.phrases.Phraser(trigram_phrases)\n",
    "data_bigrams = make_bigrams(words,bigram)\n",
    "data_bigrams_trigrams = make_trigrams(data_bigrams,bigram,trigram)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T20:07:42.681112600Z",
     "start_time": "2024-05-06T20:07:40.592278700Z"
    }
   },
   "id": "71cccd7184bb6b19",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "texts = data_bigrams_trigrams #for easier typing\n",
    "custom_stopwords = {'god','bless','tunisia','la','ly','et','al','fy','mn','mei'}  # Add any additional stop words to this set\n",
    "stopwords = STOPWORDS.union(custom_stopwords)\n",
    "filtered_texts = []\n",
    "for text in texts:\n",
    "    filtered_text = [word for word in text if word not in stopwords]\n",
    "    filtered_texts.append(filtered_text)\n",
    "texts=filtered_texts\n",
    "# print(texts)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T20:07:42.697373300Z",
     "start_time": "2024-05-06T20:07:42.683621Z"
    }
   },
   "id": "2fe33c7f3f3c0288",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# # #TF-IDF REMOVAL\n",
    "from gensim.models import TfidfModel\n",
    "# \n",
    "id2word = corpora.Dictionary(texts)\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "tfidf = TfidfModel(corpus, id2word=id2word,smartirs='ntc')\n",
    "\n",
    "low_value =0.0005\n",
    "words  = []\n",
    "words_missing_in_tfidf = []\n",
    "for i in range(0, len(corpus)):\n",
    "    bow = corpus[i]\n",
    "    low_value_words = []\n",
    "    tfidf_ids = [id for id, value in tfidf[bow]]\n",
    "    bow_ids = [id for id, value in bow]\n",
    "    low_value_words = [id for id, value in tfidf[bow] if value < low_value]\n",
    "    drops = low_value_words+words_missing_in_tfidf\n",
    "    for item in drops:\n",
    "        words.append(id2word[item])\n",
    "    words_missing_in_tfidf = [id for id in bow_ids if id not in tfidf_ids] # The words with tf-idf socre 0 will be missing\n",
    "    new_bow = [b for b in bow if b[0] not in low_value_words and b[0] not in words_missing_in_tfidf]\n",
    "    corpus[i] = new_bow\n",
    "\n",
    "# print(corpus)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T20:07:43.470722300Z",
     "start_time": "2024-05-06T20:07:42.706934400Z"
    }
   },
   "id": "49e0dccc4dcdbeae",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "lda_model=gensim.models.ldamodel.LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    num_topics=5,\n",
    "    random_state=50,\n",
    "    chunksize=1000,\n",
    "    update_every=1,\n",
    "    passes=1,\n",
    "    alpha=0.01,\n",
    "    eta=0.002,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T20:07:43.625943700Z",
     "start_time": "2024-05-06T20:07:43.471464Z"
    }
   },
   "id": "3d17ec4521d227dc",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word, mds=\"mmds\", R=30,lambda_step=0.01)\n",
    "vis"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T20:07:49.601562100Z",
     "start_time": "2024-05-06T20:07:43.626945100Z"
    }
   },
   "id": "b30a72a83fce784a",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
